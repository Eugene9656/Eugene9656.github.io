<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Ubuntu18下的Hadoop2-6-5单节点集群搭建</title>
    <url>/2019/12/17/Ubuntu18%E4%B8%8B%E7%9A%84Hadoop2-6-5%E5%8D%95%E8%8A%82%E7%82%B9%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/</url>
    <content><![CDATA[<h2 id="一、准备">一、准备</h2>
<h3 id="1-1创建Hadoop用户">1.1创建Hadoop用户</h3>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> sudo useradd -m hadoop -s /bin/bash  <span class="comment">#创建hadoop用户，并使用/bin/bash作为shell</span></span></span><br><span class="line"><span class="meta">$</span><span class="bash"> sudo passwd hadoop                   <span class="comment">#为hadoop用户设置密码，之后需要连续输入两次密码</span></span></span><br><span class="line"><span class="meta">$</span><span class="bash"> sudo adduser hadoop sudo             <span class="comment">#为hadoop用户增加管理员权限</span></span></span><br><span class="line"><span class="meta">$</span><span class="bash"> su - hadoop                          <span class="comment">#切换当前用户为用户hadoop</span></span></span><br><span class="line"><span class="meta">$</span><span class="bash"> sudo apt-get update                  <span class="comment">#更新软件包信息</span></span></span><br></pre></td></tr></table></figure>
<h3 id="1-2设置SSH无密码登录">1.2设置SSH无密码登录</h3>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> sudo apt-get install openssh-server   <span class="comment">#安装SSH server</span></span></span><br><span class="line"><span class="meta">$</span><span class="bash"> ssh localhost                         <span class="comment">#登陆SSH，第一次登陆输入yes</span></span></span><br><span class="line"><span class="meta">$</span><span class="bash"> <span class="built_in">exit</span>                                  <span class="comment">#退出登录的ssh localhost</span></span></span><br><span class="line"><span class="meta">$</span><span class="bash"> <span class="built_in">cd</span> ~/.ssh/                            <span class="comment">#如果没法进入该目录，执行一次ssh localhost</span></span></span><br><span class="line"><span class="meta">$</span><span class="bash"> ssh-keygen -t rsa　                <span class="comment">#产生秘钥进行后续身份验证，需三次回车确认</span></span></span><br></pre></td></tr></table></figure>
<p>将产生的Key放到许可证文件中</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> cat ./id_rsa.pub &gt;&gt; ./authorized_keys <span class="comment">#加入授权</span></span></span><br><span class="line"><span class="meta">$</span><span class="bash"> ssh localhost                         <span class="comment">#此时已不需密码即可登录localhost</span></span></span><br></pre></td></tr></table></figure>
<h2 id="二、安装JDK">二、安装JDK</h2>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> java -version				                    <span class="comment">#查看当前java版本，未出现版本信息代表未安装</span></span></span><br><span class="line"><span class="meta">$</span><span class="bash"> sudo apt-get install default-jdk		<span class="comment">#使用apt-get安装JDK</span></span></span><br><span class="line"><span class="meta">$</span><span class="bash"> java -version                               <span class="comment">#再次查询Java版本，查看是否安装成功</span></span></span><br></pre></td></tr></table></figure>
<p>查询java安装路径路径，记住该路径，下面步骤中的配置要用到</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> update-alternatives --display java</span></span><br></pre></td></tr></table></figure>
<p><img src="/2019/12/17/Ubuntu18%E4%B8%8B%E7%9A%84Hadoop2-6-5%E5%8D%95%E8%8A%82%E7%82%B9%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/1847_1.png" alt="1847_1.png"></p>
<h2 id="三、下载安装Hadoop">三、下载安装Hadoop</h2>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> Wget http://archive.apache.org/dist/hadoop/core/hadoop-2.6.4/hadoop-2.6.4.tar.gz    <span class="comment">#下载hadoop</span></span></span><br><span class="line"><span class="meta">$</span><span class="bash"> sudo tar -zxvf hadoop-2.6.4.tar.gz         <span class="comment">#解压缩</span></span></span><br><span class="line"><span class="meta">$</span><span class="bash"> sudo mv hadoop-2.6.4 /usr/<span class="built_in">local</span>/hadoop  <span class="comment">#将hadoop移动到/usr/local/hadoop</span></span></span><br><span class="line"><span class="meta">$</span><span class="bash"> ll  /usr/<span class="built_in">local</span>/hadoop                       <span class="comment">#查看hadoop安装目录</span></span></span><br></pre></td></tr></table></figure>
<p><img src="/2019/12/17/Ubuntu18%E4%B8%8B%E7%9A%84Hadoop2-6-5%E5%8D%95%E8%8A%82%E7%82%B9%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/1849_1.png" alt="1849_1.png"></p>
<ul>
<li>bin是运行文件目录，包括Hadoop、HDFS和YARN</li>
<li>sbin是shell文件目录，<a href="http://xn--start-all-zp6on31l.sh" target="_blank" rel="noopener">包括start-all.sh</a>、<a href="http://stop-all.sh" target="_blank" rel="noopener">stop-all.sh</a></li>
<li>etc/hadoop目录包含hadoop配置文件</li>
<li>lib是hadoop函数库目录</li>
<li>logs系统日志目录</li>
</ul>
<h2 id="四、设置Hadoop环境变量">四、设置Hadoop环境变量</h2>
<p>在终端输入命令打开编辑器</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> sudo gedit ~/.bashrc</span></span><br></pre></td></tr></table></figure>
<p>在编辑器中输入下面内容</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 设置jdk安装路径，参考安装jdk的部分输出的路径</span></span><br><span class="line">export JAVA_HOME=/usr/lib/jvm/java<span class="number">-8</span>-openjdk-amd64</span><br><span class="line"><span class="comment"># 设置HADOOP_HOME为安装路径</span></span><br><span class="line">export HADOOP_HOME=/usr/local/hadoop</span><br><span class="line"><span class="comment">#设置PATH</span></span><br><span class="line">export PATH=$PATH:$HADOOP_HOME/bin</span><br><span class="line">export PATH=$PATH:$HADOOP_HOME/sbin</span><br><span class="line"><span class="comment"># 其他环境变量</span></span><br><span class="line">export CLASSPATH=$($HADOOP_HOME/bin/hadoop classpath):$CLASSPATH</span><br><span class="line">export HADOOP_MAPRED_HOME=$HADOOP_HOME</span><br><span class="line">export HADOOP_COMMON_HOME=$HADOOP_HOME</span><br><span class="line">export HADOOP_HDFS_HOME=$HADOOP_HOME</span><br><span class="line">export YARN_HOME=$HADOOP_HOME</span><br><span class="line"><span class="comment"># 连接库相关设置</span></span><br><span class="line">export HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/native</span><br><span class="line">export HADOOP_OPTS=<span class="string">"-DJava.library.path=$HADOOP_HOME/lib"</span></span><br><span class="line">export JAVA_LIBRARY_PATH=$HADOOP_HOME/lib/native:$JAVA_LIBRARY_PATH</span><br></pre></td></tr></table></figure>
<p>在编辑器中输入后，然后按ctrl+s保存，再关闭编辑器
<img src="/2019/12/17/Ubuntu18%E4%B8%8B%E7%9A%84Hadoop2-6-5%E5%8D%95%E8%8A%82%E7%82%B9%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/1851_1.png" alt="1851_1.png"></p>
<p>让设置立即生效</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> <span class="built_in">source</span> ~/.bashrc</span></span><br></pre></td></tr></table></figure>
<p>或者使用vim编辑器，点击键盘&quot;i&quot;, 就能开始编辑。输入配置文件内容后，点击键盘&quot;esc&quot;键，然后输入<code>：wq</code>来保存退出</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> sudo vim --version              <span class="comment">#检查是否安装vim</span></span></span><br><span class="line"><span class="meta">$</span><span class="bash"> sudo apt-get install vim      <span class="comment">#安装vim</span></span></span><br><span class="line"><span class="meta">$</span><span class="bash"> sudo vim ~/.bashrc              <span class="comment">#编辑.bashrc</span></span></span><br></pre></td></tr></table></figure>
<p><img src="/2019/12/17/Ubuntu18%E4%B8%8B%E7%9A%84Hadoop2-6-5%E5%8D%95%E8%8A%82%E7%82%B9%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/1853_1.png" alt="1853_1.png"></p>
<h2 id="五、修改Hadoop配置文件">五、修改Hadoop配置文件</h2>
<p><a href="http://xn--hadoop-env-0840as06l.sh" target="_blank" rel="noopener">编辑hadoop-env.sh</a></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> sudo gedit /usr/<span class="built_in">local</span>/hadoop/etc/hadoop/hadoop-env.sh</span></span><br></pre></td></tr></table></figure>
<p>设置JAVA_HOME的路径，参考安装jdk的部分输出的路径，编辑完成保存退出
<img src="/2019/12/17/Ubuntu18%E4%B8%8B%E7%9A%84Hadoop2-6-5%E5%8D%95%E8%8A%82%E7%82%B9%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/1855_1.png" alt="1855_1.png"></p>
<p>修改core-site.xml文件</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">             <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">             <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:/usr/local/hadoop/hadoop_data<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">             <span class="tag">&lt;<span class="name">description</span>&gt;</span>Abase for other temporary directories.<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">             <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.default.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">             <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://localhost:9000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> sudo gedit /usr/<span class="built_in">local</span>/hadoop/etc/hadoop/core-site.xml</span></span><br></pre></td></tr></table></figure>
<p>第一个节点是临时目录，第二个节点是HDFS默认名称
<img src="/2019/12/17/Ubuntu18%E4%B8%8B%E7%9A%84Hadoop2-6-5%E5%8D%95%E8%8A%82%E7%82%B9%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/1857_1.png" alt="1857_1.png"></p>
<p>编辑yarn-site.xml</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- Site specific YARN configuration properties --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">             <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">             <span class="tag">&lt;<span class="name">value</span>&gt;</span>mapreduce_shuffle<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">             <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services.mapreduce.shuffle.class<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">             <span class="tag">&lt;<span class="name">value</span>&gt;</span>org.apache.hadoop.mapred.ShuffleHandler<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> sudo gedit /usr/<span class="built_in">local</span>/hadoop/etc/hadoop/yarn-site.xml</span></span><br></pre></td></tr></table></figure>
<p><img src="/2019/12/17/Ubuntu18%E4%B8%8B%E7%9A%84Hadoop2-6-5%E5%8D%95%E8%8A%82%E7%82%B9%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/1863_1.png" alt="1863_1.png"></p>
<p>编辑mapred-site.xml，mapred-site.xml用于监控Map与Reduce程序的JobTracker任务分配情况以及TaskTracker任务运行情况</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">             <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.framework.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">             <span class="tag">&lt;<span class="name">value</span>&gt;</span>yarn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> sudo cp /usr/<span class="built_in">local</span>/hadoop/etc/hadoop/mapred-site.xml.template /usr/<span class="built_in">local</span>/hadoop/etc/hadoop/mapred-site.xml            <span class="comment">#复制模板文件</span></span></span><br><span class="line"><span class="meta">$</span><span class="bash"> sudo gedit /usr/<span class="built_in">local</span>/hadoop/etc/hadoop/mapred-site.xml</span></span><br></pre></td></tr></table></figure>
<p>这个节点是设置mapreduce框架为yarn
<img src="/2019/12/17/Ubuntu18%E4%B8%8B%E7%9A%84Hadoop2-6-5%E5%8D%95%E8%8A%82%E7%82%B9%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/1865_1.png" alt="1865_1.png"></p>
<p>编辑 hdfs-site.xml</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		   <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.replication<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		   <span class="tag">&lt;<span class="name">value</span>&gt;</span>1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		   <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.name.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		   <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:/usr/local/hadoop/hadoop_data/hdfs/namenode<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		   <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.datanode.data.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		   <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:/usr/local/hadoop/hadoop_data/hdfs/datanode<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> sudo gedit /usr/<span class="built_in">local</span>/hadoop/etc/hadoop/hdfs-site.xml</span></span><br></pre></td></tr></table></figure>
<p>第一个节点是设置blocks副本备份数量，第二个是NameNode数据存储目录，第三个是DataNode数据存储目录
<img src="/2019/12/17/Ubuntu18%E4%B8%8B%E7%9A%84Hadoop2-6-5%E5%8D%95%E8%8A%82%E7%82%B9%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/1867_1.png" alt="1867_1.png"></p>
<h2 id="六、创建并格式化HDFS目录">六、创建并格式化HDFS目录</h2>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> sudo mkdir -p /usr/<span class="built_in">local</span>/hadoop/hadoop_data/hdfs/namenode   <span class="comment">#创建namenode数据存储目录</span></span></span><br><span class="line"><span class="meta">$</span><span class="bash"> sudo mkdir -p /usr/<span class="built_in">local</span>/hadoop/hadoop_data/hdfs/datanode   <span class="comment">#创建datanode数据存储目录</span></span></span><br><span class="line"><span class="meta">$</span><span class="bash"> sudo chwn -R hadoop /usr/<span class="built_in">local</span>/hadoop               <span class="comment">#修改Hadoop目录所有者为hadoop</span></span></span><br><span class="line"><span class="meta">$</span><span class="bash"> hadoop namenode -format                             <span class="comment">#格式化HDFS</span></span></span><br></pre></td></tr></table></figure>
<h2 id="七、启动Hadoop">七、启动Hadoop</h2>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> start-dfs.sh                    <span class="comment">#启动HDFS</span></span></span><br><span class="line"><span class="meta">$</span><span class="bash"> start-yarn.sh                   <span class="comment">#启动Hadoop MapReduce框架Yarn</span></span></span><br></pre></td></tr></table></figure>
<p>或者同时启动</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> start-all.sh</span></span><br></pre></td></tr></table></figure>
<p>输入<code>jps</code>查看进程是否启动
<img src="/2019/12/17/Ubuntu18%E4%B8%8B%E7%9A%84Hadoop2-6-5%E5%8D%95%E8%8A%82%E7%82%B9%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/1869_1.png" alt="1869_1.png"></p>
<p>查看Hadoop ResourceManager Web页面，打开浏览器输入 <a href="http://localhost:8088/" target="_blank" rel="noopener">http://localhost:8088/</a>
<img src="/2019/12/17/Ubuntu18%E4%B8%8B%E7%9A%84Hadoop2-6-5%E5%8D%95%E8%8A%82%E7%82%B9%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/1871_1.png" alt="1871_1.png"></p>
<p>查看NameNode HDFS Web页面，打开浏览器输入 <a href="http://localhost:50070/" target="_blank" rel="noopener">http://localhost:50070/</a>
<img src="/2019/12/17/Ubuntu18%E4%B8%8B%E7%9A%84Hadoop2-6-5%E5%8D%95%E8%8A%82%E7%82%B9%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/1873_1.png" alt="1873_1.png"></p>
<h2 id="八、遇到的问题和解决办法">八、遇到的问题和解决办法</h2>
<p>在安装完成后发现namenode进程没有启动，打不开 <a href="http://localhost:50070/" target="_blank" rel="noopener">http://localhost:50070/</a> 页面。首先去查看日志</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ cd &#x2F;usr&#x2F;local&#x2F;hadoop&#x2F;logs                 #进入日志目录</span><br><span class="line">$ sz hadoop-hadoop-namenode-csubuntu.log      #下载日志</span><br></pre></td></tr></table></figure>
<p><img src="/2019/12/17/Ubuntu18%E4%B8%8B%E7%9A%84Hadoop2-6-5%E5%8D%95%E8%8A%82%E7%82%B9%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/2006_1.png" alt="2006_1.png"></p>
<p>发现是9000端口被占用</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo netstat -lnp | grep 9000           #查看9000端口占用</span><br></pre></td></tr></table></figure>
<p><img src="/2019/12/17/Ubuntu18%E4%B8%8B%E7%9A%84Hadoop2-6-5%E5%8D%95%E8%8A%82%E7%82%B9%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/2010_1.png" alt="2010_1.png"></p>
<p>看到是nginx占用了9000端口,把nginx停止就能重新启动hadoop</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ ps -ef | grep nginx                       #查看nginx主进程</span><br><span class="line">$ kill -9 主进程号                          #强制停止Nginx</span><br></pre></td></tr></table></figure>
<p><img src="/2019/12/17/Ubuntu18%E4%B8%8B%E7%9A%84Hadoop2-6-5%E5%8D%95%E8%8A%82%E7%82%B9%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/2012_1.png" alt="2012_1.png"></p>
<p>启动hadoop守护进程
<img src="/2019/12/17/Ubuntu18%E4%B8%8B%E7%9A%84Hadoop2-6-5%E5%8D%95%E8%8A%82%E7%82%B9%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/2014_1.png" alt="2014_1.png"></p>
]]></content>
      <categories>
        <category>环境搭建</category>
      </categories>
      <tags>
        <tag>hadoop</tag>
        <tag>hdfs</tag>
        <tag>ubuntu</tag>
      </tags>
  </entry>
  <entry>
    <title>Hello World</title>
    <url>/2019/12/13/hello-world/</url>
    <content><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p>
<h2 id="Quick-Start">Quick Start</h2>
<h3 id="Create-a-new-post">Create a new post</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p>
<h3 id="Run-server">Run server</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p>
<h3 id="Generate-static-files">Generate static files</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p>
<h3 id="Deploy-to-remote-sites">Deploy to remote sites</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/one-command-deployment.html" target="_blank" rel="noopener">Deployment</a></p>
]]></content>
  </entry>
</search>
